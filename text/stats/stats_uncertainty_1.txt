Now that we've got those pesky p-values sorted, I want to highlight some further important principles of statistical inference. The purpose of statistical inference is of course to help us make decisions using data. However, we shouldn't forget that inference is an uncertain conclusion and our interpretations of the results from statistical analyses always need to take that uncertainty into account. Let's explore this concept by going further with the leadership capability example we covered in the last series of videos.

After constructing a null distribution based on our null hypothesis that there was no difference in mean leadership scores between masters and bachelors degree prepared nurses, we were able to calculate a p-value, which led us to the conclusion that we should reject the null hypothesis. So although we've been able to make a judgement that the the true mean difference between these groups is not ZERO, in the population, we're really no closer to figuring out what the TRUE mean difference in leadership score between masters and bachelors degree prepared nurses actually is. To gain more insight into this, we can now revisit a concept we've already covered - and that is confidence intervals. 

Hopefully you'll recall from the earlier videos that a confidence interval is constructed from the standard error, and the standard error is a measure of the spread of a sampling distribution. The region within two standard errors will cover ninety five percent of the sampling distribution, so we can use the formula mean plus or minus two times standard error to calculate the lower and upper confidence intervals. 