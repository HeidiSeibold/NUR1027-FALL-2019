I think for you to properly interpret regression coefficients, you need to have a basic understanding of what linear regression actually is. To demonstrate, let's consider the example from my previous research that we looked at previously to learn about validity.

This plot shows quality of life on the vertical axis and depression scores on the horizintal axis of a sample of heart transplant recipients. Quality of life was measured with the SF thirty six on a scale from zero to one hundred with higher scores indicating better quality of life. Depression was measured with the PHQ-nine on a scale from zero to twenty five with higher scores indicating worse depression. What we can see by just visually inspecting the data, is that there may be a negative correlation between these two measures because the clustering of scores at the top left make it seem like patients who had higher quality of life may have had lower depression scores. Linear regression provides us with insights into the relationship between an outcome and predictor variable by finding the line of best fit between all these points. In our case, the outcome is quality of life and the predictor is depression.

This is what the regression line looks like. We can see that it indeed does kind of slope down from the top left of the plot, just as we suspected it might do. If we calculate the regression coefficients, we will be able to quantify this linear relationship between the outcome and predictor variable. The coefficients we calculate will be one coefficient for the intercept and a coefficient for the slope. The intercept is the point at which the regression line crosses the vertical axis. In this case, it is 67.  The slope coefficient will tell us the magnitude of change that we should expect to see in the outcome variable for each unit increase in the predictor variable. Let's take a closer look at the slope coefficient.