---
output:
  xaringan::moon_reader:
    seal: false
    lib_dir: libs
    css: [default, fonts.css, animate.css]
    nature:
      ratio: '16:9'
    includes:
      in_header: fa.html
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(tidyverse)
library(infer)
```

class: center, middle, hide-count

## Clinical significance and p-values

???

Now that we understand the differences in pvalues and confidence intervals, hopefully it is also clear to you that the conclusions we can draw from confidence intervals are very much different from what we can draw from a p-value. A p value only tells us the probability of obtaining a result as or more extreme as the sample result IF the null hypothesis were true.

---
class: left, middle, hide-count

### Although P values may be provided in addition to confidence intervals, results should not be reported solely as P values.

>CONSORT Guidelines

???

Because of this major limitation of p values, reporting guidelines for research, such as the CONSORT guidelines for reporting randomized controlled trials, recommend that researchers should never JUST report p-values. Confidence intervals should always be reported so that users of research, such as yourselves, can judge the clinical signficance of the result, given the uncertainty surrounding the sample estimate. So I can't stress enough to you that whenever you see a p-value reported in a research paper without a confidence interval, we need to be very cautious about how we may use that information to guide decision-making.  

---

class: left, middle, hide-count

```{r include=FALSE}
rgbeta <- function(n, mean, var, min = 0, max = 1)
{
  dmin <- mean - min
  dmax <- max - mean
  
  if (dmin <= 0 || dmax <= 0)
  {
    stop(paste("mean must be between min =", min, "and max =", max)) 
  }
  
  if (var >= dmin * dmax)
  {
    stop(paste("var must be less than (mean - min) * (max - mean) =", dmin * dmax))
  }
  
  # mean and variance of the standard beta distributed variable
  mx <- (mean - min) / (max - min)
  vx <- var / (max - min)^2
  
  # find the corresponding alpha-beta parameterization
  a <- ((1 - mx) / vx - 1 / mx) * mx^2
  b <- a * (1 / mx - 1)
  
  # generate standard beta observations and transform
  x <- rbeta(n, a, b)
  y <- (max - min) * x + min
  
  return(y)
}
```

```{r include=FALSE}
set.seed(272)
masters <- data.frame(leadership = rgbeta(n=100, mean=8, var=5^2, min = 3, max = 15),
                      degree = "Masters")
non_masters <- data.frame(leadership = rgbeta(n=100, mean=6.5, var=5^2, min = 3, max = 15),
                          degree = "Bachelors")
data <- rbind(masters, non_masters)

d_hat <- data %>% 
  specify(leadership ~ degree) %>% 
  calculate("diff in means", order = c("Masters", "Bachelors"))
```

```{r include=FALSE}
unpaired_mean_diff <- dabestr::dabest(data, degree, leadership,
                             idx = c("Bachelors", "Masters"),
                             paired = FALSE, reps = 1000, seed = 272)
```

.left-column[

```{r echo=FALSE, fig.height=5, fig.retina=8}
bootstaps <- data.frame(stat = c(unlist(unpaired_mean_diff$result$bootstraps))) 

bootplot <- bootstaps%>% 
  ggplot2::ggplot(aes(stat)) +
  geom_dotplot(binwidth=0.075, method='histodot', colour = "white", fill = "blue", alpha=0.3) +
  scale_y_continuous(limits = c(0,1))+
  scale_x_continuous(limits = c(-2.5,5), breaks = c(-2, -1, 0, 1, 2, 3))+
  theme_minimal()+
  labs(x = "Difference in mean leadership score between groups", y = NULL)+
  geom_vline(xintercept = 0, size = 1, color = "black")+
  labs(x = "Difference in mean leadership score between groups", y = NULL, title = "")+
      geom_vline(xintercept = 1.82, size = 1, color = "red", linetype = "dashed" )+
  coord_cartesian(clip="off")+
  geom_text(
    x = -1.5,
    y = 1.1,
    inherit.aes = FALSE,
    label = "Higher in Bachelors group",
    check_overlap = TRUE,
    hjust = "center",
    fontface = 'bold',
    size = 5
  ) +
  geom_text(
    x = 1.8,
    y = 1.1,
    inherit.aes = FALSE,
    label = "Higher in Masters group",
    check_overlap = TRUE,
    hjust = "center",
    fontface = 'bold',
    size = 5
  )

bootplot+
       annotate("rect", xmin = d_hat$stat, xmax = unpaired_mean_diff$result$bca_ci_high, ymin = 0, ymax = Inf,
        alpha = .2, fill = "red") +
   annotate("rect", xmin = unpaired_mean_diff$result$bca_ci_low, xmax = d_hat$stat, ymin = 0, ymax = Inf,
        alpha = .2, fill = "red") +
  geom_errorbarh(aes(y = 0.8, xmax = unpaired_mean_diff$result$bca_ci_high, xmin = unpaired_mean_diff$result$bca_ci_low, height = .2))+
    annotate(geom = "text", x = unpaired_mean_diff$result$bca_ci_high, y = 0.93, label = round(unpaired_mean_diff$result$bca_ci_high, 1), hjust = "center", size = 5)+
    annotate(geom = "text", x = unpaired_mean_diff$result$bca_ci_low, y = 0.93, label = round(unpaired_mean_diff$result$bca_ci_low, 1), hjust = "center", size = 5)
```

Broad confidence intervals mean that the effect of having a masters degree on leadership could be **really small** or **really large** in the population

]

???


Let's talk a bit more about how useful confidence intervals are for informing decision-making. Consider the result of our hypothetical study of leadership in nurses with and without masters degrees. The 95% confidence intervals actually spanned quite a large range from only zero point four points higher to about three points higher in the masters group. This means we have to consider the potential that the effect of having a masters degree on leadership could be either really small or really large in the population and base our decision about whether or not it is a good idea to go to grad school with that degree of uncertainty in mind. What would have complicated things further, is if the confidence interval had crossed the zero point, indicating that in the population there was the potential that having a masters degree could be associated with either lower or higher leadership capability.

---
class: left, top, hide-count

###<i class="fad fa-skull-crossbones"></i> Be wary of judgements made in research reports based on p values without confidence intervals

###<i class="fad fa-exchange-alt"></i> The degree of uncertainty associated with a sample estimate should be considered in decision-making (based on the **entire range** of the confidence intervals) 


???

So just to recap - we need to be cautious about interpreting the results of statical inferences in studies if only a p value is reported. And it is good practice to account for the uncertainty associated with a result by considering the ENTIRE range of the confidene interval when using statistical inferences to inform decision-making in nursing and healthcare.