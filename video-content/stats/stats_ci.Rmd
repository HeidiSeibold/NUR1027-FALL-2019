---
output:
  xaringan::moon_reader:
    seal: false
    lib_dir: libs
    css: [default, fonts.css, animate.css]
    ratio: '16:9'
    includes:
      in_header: fa.html
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(tidyverse)
set.seed(3)
```

class: left, middle, hide-count
.pull-left[
```{r  echo=FALSE, message= FALSE, warning=FALSE, cache = TRUE}
library(ggplot2)

plot_hist <- function(N){
  m <- do.call(rbind, lapply(1:1000, function(x) mean(rnorm(N, 10, 2))))
  m <- as.data.frame(m)
  colnames(m) <- "Height"
  ggplot(data = m, aes(x = Height)) +
  geom_histogram(binwidth = 0.1, color = "white", fill="green3") +
  theme_light() +
  scale_y_continuous(expand = c(0,0)) +
  xlim(5,15) + 
  labs(x=paste0("Sample means N = ", N), y="Frequency") +
  theme(panel.border=element_blank(), panel.grid.minor=element_blank())  
}
cowplot::plot_grid(plot_hist(5),plot_hist(50),plot_hist(500), ncol = 1, align = "hv") 
```
]
--
<center>
*Distributions based on smaller samples should have larger standard deviations*

--

*Standard error of the mean (SEM) - or just standard error for short*

--
### SEM = SD/sqrt(N)
<center>


???

So we've established that we can tell pretty easily from just looking at the plots that sampling distributions are more spread out if they are drawn from samples of smaller sizes. But what we really need, is a way to summarize this spread of sampling distributions with a single value. Fortunately, we've already learned how to quantify a measure of spread like this - and that is the standard deviation. The difference here, is that when you calculate the standard deviation of a sampling distribution of mean values, you are calculating what is called the standard error of the mean, or just “standard error”. The standard error is the value that we use to capture the level of precision of our sample estimate. 

---

class: center, middle, hide-count

# How do we apply the SEM

???

Now that we have a better understanding of how to gauge the precision of our sample estimates, we can use this information to make inferences about populations based upon data that we have drawn from just a sample. To formally make inferences, we need to revisit a principle about the normal distribution that we've already covered and apply it to construct confidence intervals. This is a concept that I'm sure you've come across before.

---

class: left, top, hide-count

<img src="General_empirical.jpg" />

## 95% CI = sample mean ± 2*SEM


???

But what you may not know, is that confidence intervals are calculated from the standard error. And remember, the standard error is just the standard deviation of the sampling distribution. So, we can interpret the interval between two standard errors above and below the sample mean as capturing about ninety five percent of the sampling distribution. And this is what we use to construct a ninety five percent confidence interval. The upper limit of the confidence interval is the sample mean plus two standard erros and the lower limit is the sample mean minus two standard errors. 

---
class: left, middle, hide-count

### 95% CI spans the range of values that we are 95% confident contains the **true** mean of the **population**

???

And the best way to interpret this, is that a ninety five percent confidence interval spans the range of values that we are ninety five percent confident contains the true mean of the population. 


---

class: center, middle, hide-count
# Up next

???

Just to cement what we've learnt, have a go in the next exercise at calculating ninety-five percent confidence intervals. 