---
output:
  xaringan::moon_reader:
    seal: false
    lib_dir: libs
    css: [default, fonts.css, animate.css]
    nature:
      slideNumberFormat: |
        <div class="progress-bar-container">
          <div class="progress-bar" style="width: calc(%current% / %total% * 100%);">
          </div>
        </div>
      ratio: '16:9'
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(icon)
library(emo)
library(tidyverse)
library(ggplot2)
knitr::opts_chunk$set( fig.height=5) 
set.seed(3)
```
class: top, left
# Flipping 10 coins

```{r}
flips <- rbinom(10000,10,0.5)
```

```{r echo=FALSE}
suppressMessages(library(ggplot2))
options(warn=-1)
tibble::tibble(flips) %>% 
  mutate(Bet = ifelse(flips<=4, "Chances you win", "Chances you lose")) %>% 
ggplot2::ggplot(aes(flips))+
  geom_histogram(binwidth = 0.5)
```

???

So far we've often looked at binomial consisting of 10 flips of a coin that has a fifty percent chance of heads. That would look like this distribution - a histogram where the most common value is five. 

---
class: top, left
# Flipping 1000 coins

```{r}
flips <- rbinom(10000,1000,0.5)
```

```{r echo=FALSE}
suppressMessages(library(ggplot2))
options(warn=-1)
tibble::tibble(flips) %>% 
  mutate(Bet = ifelse(flips<=4, "Chances you win", "Chances you lose")) %>% 
ggplot2::ggplot(aes(flips))+
  geom_histogram(aes(y=..density..), colour=alpha("gray", 0.4), fill = alpha("gray", 0.4), binwidth = 4)+
 geom_density(color = alpha("#FF6666", 0), alpha = 0.2, fill="#FF6666")+
  theme_minimal()+
  theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank())+ geom_hline(yintercept=0, colour="white", size=1)
```

???

Now instead imagine that we've flipped one thousand coins ten thousand times. Now the distribution of heads is centered around 500. Notice the distribution is now taking on a sort of symmetrical bell curve shape. This is because when you draw from a binomial with a very large size, that is, many coin flips, the result approximates a normal distribution. This normal distribution is famous because many distributions in nature take this shape, including measurement errors in scientific experiments, which we learned about in the chapter on measurement. Most of the common statisical analysis methods you'll come across in quantitative research studies are based on the normal distribution. 

---
class: top, left
# Normal distribution has mean and standard deviation

```{r echo=FALSE}
suppressMessages(library(ggplot2))
options(warn=-1)
tibble::tibble(flips) %>% 
  mutate(Bet = ifelse(flips<=4, "Chances you win", "Chances you lose")) %>% 
ggplot2::ggplot(aes(flips))+
  geom_histogram(aes(y=..density..), colour=alpha("gray", 0.4), fill = alpha("gray", 0.4), binwidth = 4)+
 geom_density(color = alpha("#FF6666", 0), alpha = 0.2, fill="#FF6666")+
  theme_minimal()+
  theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank())+ geom_hline(yintercept=0, colour="white", size=1)+
  geom_vline(xintercept=500,linetype="dashed", color = "gray", size = 1)+
  annotate("text", colour = "white", size = 12, x = 500, y = 0.010, label = "mean")+
  annotate("text", colour = "white", size = 12, x = 510, y = 0.005, label = "sd")
```

???

While the binomial is determined by the parameters size and p, that is the number of flips and their probability of heads, the normal is defined by two other parameters, the mean and standard deviation. The mean of course is just the sum of observations divided by the sample size. The standard deviation is a measure of how spread out the data are. Calculating the standard deviation is a little more complicated than the mean and it's not important to know how to do this by hand.  

---
class: top, left
# Meaning of the standard deviation

<img src="General_empirical.jpg" width="80%"/>

???

What is important is how we can apply the standard deviation in a useful way to normal distributions to predict how “rare” or “common” particular observations in a data set may be. For the normal distribution, almost all of the data will fall within three standard deviations above and below the mean. The interval created by one standard deviation above and below the mean includes sixty eight percent of all the data. So observations within these bounds would be fairly common, but it would not be exceedingly rare to observe data that fall outside of these bounds. Two standard deviations above and below the mean encompasses approximately ninety five percent of the data. Observations that fall within these bounds include the common and also infrequent observations. Observations that fall outside of two standard deviations would be uncommon.

---
class: center, middle

# Let's practice

???

In the next exercises, we'll go through some calculations to demonstrate to you how our knowledge about probability and the normal distribution can be used to find out how likely it is to observe particular observations in a dataset.
