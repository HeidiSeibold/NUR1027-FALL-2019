---
output:
  xaringan::moon_reader:
    seal: false
    lib_dir: libs
    css: [default, fonts.css, animate.css]
    nature:
      highlightStyle: github
      highlightLines: true
      ratio: '16:9'
    includes:
      in_header: fa.html
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(tidyverse)
library(infer)
```

class: left, top, hide-count

## Statistical Inference

A **statistical inference** helps to make decisions using data.


But...

An *inference* is an uncertain conclusion.

???

Now that we've got those pesky p-values sorted, I want to highlight some further important principles of statistical inference. The purpose of statistical inference is of course to help us make decisions using data. However, we shouldn't forget that inference is an uncertain conclusion and our interpretations of the results from statistical analyses always need to take that uncertainty into account. Let's explore this concept by going further with the leadership capability example we covered in the last series of videos.

---
class: middle, left, hide-count
```{r include=FALSE}
rgbeta <- function(n, mean, var, min = 0, max = 1)
{
  dmin <- mean - min
  dmax <- max - mean
  
  if (dmin <= 0 || dmax <= 0)
  {
    stop(paste("mean must be between min =", min, "and max =", max)) 
  }
  
  if (var >= dmin * dmax)
  {
    stop(paste("var must be less than (mean - min) * (max - mean) =", dmin * dmax))
  }
  
  # mean and variance of the standard beta distributed variable
  mx <- (mean - min) / (max - min)
  vx <- var / (max - min)^2
  
  # find the corresponding alpha-beta parameterization
  a <- ((1 - mx) / vx - 1 / mx) * mx^2
  b <- a * (1 / mx - 1)
  
  # generate standard beta observations and transform
  x <- rbeta(n, a, b)
  y <- (max - min) * x + min
  
  return(y)
}
```

```{r include=FALSE}
set.seed(272)
masters <- data.frame(leadership = rgbeta(n=100, mean=8, var=5^2, min = 3, max = 15),
                      degree = "Masters")
non_masters <- data.frame(leadership = rgbeta(n=100, mean=6.5, var=5^2, min = 3, max = 15),
                          degree = "Bachelors")
data <- rbind(masters, non_masters)

d_hat <- data %>% 
  specify(leadership ~ degree) %>% 
  calculate("diff in means", order = c("Masters", "Bachelors"))
```

```{r include=FALSE}
set.seed(272)
null_distn <- data %>% 
  specify(leadership ~ degree) %>%
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>%
    calculate(stat = "diff in means", order = c("Masters", "Bachelors"))
```
.left-column[
```{r echo=FALSE, fig.height=5, fig.retina=8}
pvaluePlot <- null_distn %>%
  ggplot2::ggplot(aes(stat)) +
  geom_dotplot(binwidth=0.075, method='histodot', colour = "white", fill = "blue", alpha=0.3) +
  scale_y_continuous(limits = c(0,1))+
  scale_x_continuous(limits = c(-2.5,3.3), breaks = c(-2, -1, 0, 1, 2, 3))+
  theme_minimal()+
  labs(x = "Difference in mean leadership score between groups", y = NULL, title = "")+
  geom_vline(xintercept = 0, size = 1, color = "black")+
      coord_cartesian(clip="off")+
  geom_text(x = -1.5, y = 1.1, label = "Lower in Masters group",
    check_overlap = TRUE, hjust = "center", fontface = 'bold', size = 5) +
  geom_text(x = 1.5, y = 1.1, inherit.aes = FALSE, label = "Higher in Masters group",
    check_overlap = TRUE, hjust = "center", fontface = 'bold', size = 5)+
      geom_vline(xintercept = 1.82, size = 1, color = "red", linetype = "dashed" )+
       annotate("rect", xmin = 1.8, xmax = Inf, ymin = 0, ymax = Inf,
        alpha = .2, fill = "red") +
   annotate("rect", xmin = -1.8, xmax = -Inf, ymin = 0, ymax = Inf,
        alpha = .2, fill = "red") +
  annotate(geom = "text", x = 2.3, y = 0.45, label = "p=0.022", hjust = "center", size = 5)+ 
  annotate(
    geom = "curve", xend = -1.3, yend = 0.25, x = -1.8, y = 0.48, 
    curvature = .3, arrow = arrow(length = unit(2, "mm"))
  ) +
  annotate(geom = "text", x = -1.8, y = 0.5, label = "Each dot is a random shuffle", hjust = "center")
pvaluePlot
```

A p-value only provided us with evidence that the mean difference in the population is **not zero**

Confidence intervals will allow us to **estimate** what the true mean difference is **in the population**
]

???

After constructing a null distribution based on our null hypothesis that there was no difference in mean leadership scores between masters and bachelors degree prepared nurses, we were able to calculate a p-value, which led us to the conclusion that we should reject the null hypothesis. So although we've been able to make a judgement that the the true mean difference between these groups is not ZERO, in the population, we're really no closer to figuring out what the TRUE mean difference in leadership score between masters and bachelors degree prepared nurses actually is. To gain more insight into this, we can now revisit a concept we've already covered - and that is confidence intervals. 
---
class: left, top, hide-count
.left-column[
<img src="General_empirical.jpg" />

95% CI = sample mean Â± 2*SEM

A 95% CI spans the range of values that we are 95% confident contains the **true** mean of the **population**
]

???

Hopefully you'll recall from the earlier videos that a confidence interval is constructed from the standard error, and the standard error is a measure of the spread of a sampling distribution. The region within two standard errors will cover ninety five percent of the sampling distribution, so we can use the formula mean plus or minus two times standard error to calculate the lower and upper confidence intervals. 
---

class: top, center, hide-count
.left-column[
.pull-left[

**Centered around zero**

```{r echo=FALSE, fig.height=6, fig.retina=8}
pvaluePlot
```
For p-values
]


.pull-right[

**Centered around mean**
```{r include=FALSE}
unpaired_mean_diff <- dabestr::dabest(data, degree, leadership,
                             idx = c("Bachelors", "Masters"),
                             paired = FALSE, reps = 1000, seed = 272)
```
```{r echo=FALSE, fig.height=6, fig.retina=8}
bootstaps <- data.frame(stat = c(unlist(unpaired_mean_diff$result$bootstraps))) 

bootplot <- bootstaps%>% 
  ggplot2::ggplot(aes(stat)) +
  geom_dotplot(binwidth=0.075, method='histodot', colour = "white", fill = "blue", alpha=0.3) +
  scale_y_continuous(limits = c(0,1))+
  scale_x_continuous(limits = c(-2.5,5), breaks = c(-2, -1, 0, 1, 2, 3))+
  theme_minimal()+
  labs(x = "Difference in mean leadership score between groups", y = NULL)+
  geom_vline(xintercept = 0, size = 1, color = "black")+
  labs(x = "Difference in mean leadership score between groups", y = NULL, title = "")+
      geom_vline(xintercept = 1.82, size = 1, color = "red", linetype = "dashed" )+
  coord_cartesian(clip="off")+
  geom_text(
    x = -1.5,
    y = 1.1,
    inherit.aes = FALSE,
    label = "Lower in Masters group",
    check_overlap = TRUE,
    hjust = "center",
    fontface = 'bold',
    size = 5
  ) +
  geom_text(
    x = 1.8,
    y = 1.1,
    inherit.aes = FALSE,
    label = "Higher in Masters group",
    check_overlap = TRUE,
    hjust = "center",
    fontface = 'bold',
    size = 5
  )
bootplot+ 
  annotate(
    geom = "curve", xend = 2.8, yend = 0.375, x = 3.5, y = 0.53, 
    curvature = .1, arrow = arrow(length = unit(2, "mm"))
  ) +
  annotate(geom = "text", x = 3.6, y = 0.55, label = "Each dot is a random shuffle", hjust = "center")
```
For confidence intervals
]
]
???

Now the null distribution, which we've already constructed is a TYPE of sampling distribution, but there is a major difference between this distribution, which we used to calculate p-values and the one we will use to construct confidence intervals. 
The null distribution that we used to calculate p-values was constructed based on the null hypothesis that there is no true difference between the two groups. And for that reason, the null distribution is centered around zero. A sampling distribution used to construct confidence intervals makes no such assumption about the null hypothesis. Instead it uses the mean difference between groups that was observed in the actual sample as the middle point of the distribution. And we can use it to construct some confidence intervals for this DIFFERENCE in mean leadership scores that we observed in our sample. Let's do that now. 
---

class: top, left, hide-count
.left-column[

<img src="General_empirical.jpg" />

```{r echo=FALSE, fig.height=5, fig.retina=8}
bootplot
```


]

???
Here's a larger view of the distribution that we're going to use to construct the confidence intervals for the mean difference that we observed between masters and bachelors degree nurses in our sample. You can see that it is centered around the red line, which is the mean difference in leadership scores observed from our sample. The region between two standard errors above and below the mean will cover ninety five percent of the distribution and give us our confidence intervals.

---
class: left, top, hide-count

.left-column[
<img src="General_empirical.jpg" />

```{r echo=FALSE, fig.height=5, fig.retina=8}
bootplot+
       annotate("rect", xmin = d_hat$stat, xmax = unpaired_mean_diff$result$bca_ci_high, ymin = 0, ymax = Inf,
        alpha = .2, fill = "red") +
   annotate("rect", xmin = unpaired_mean_diff$result$bca_ci_low, xmax = d_hat$stat, ymin = 0, ymax = Inf,
        alpha = .2, fill = "red")
```

]

???
So let's now add some shading to cover the region below the mean to the lower ninety five percent confidence interval and also the range above the mean to cover up to the upper ninety-five percent confidence interval. 

---
class: top, left, hide-count

.left-column[

```{r echo=FALSE, fig.height=5, fig.retina=8}
bootplot+
       annotate("rect", xmin = d_hat$stat, xmax = unpaired_mean_diff$result$bca_ci_high, ymin = 0, ymax = Inf,
        alpha = .2, fill = "red") +
   annotate("rect", xmin = unpaired_mean_diff$result$bca_ci_low, xmax = d_hat$stat, ymin = 0, ymax = Inf,
        alpha = .2, fill = "red") +
  geom_errorbarh(aes(y = 0.8, xmax = unpaired_mean_diff$result$bca_ci_high, xmin = unpaired_mean_diff$result$bca_ci_low, height = .2))+
    annotate(geom = "text", x = unpaired_mean_diff$result$bca_ci_high, y = 0.93, label = round(unpaired_mean_diff$result$bca_ci_high, 1), hjust = "center", size = 5)+
    annotate(geom = "text", x = unpaired_mean_diff$result$bca_ci_low, y = 0.93, label = round(unpaired_mean_diff$result$bca_ci_low, 1), hjust = "center", size = 5)
```


95% confident that the true mean difference in leadership scores between masters and bachelors degree prepared nurses <strong>in the population</strong> is within the range of being 0.4 points higher in masters nurses to 3.2 points higher in masters nurses

]

???

Now that we've done that, the conclusion that we can draw from constructing these confidence intervals is that we are ninety five percent confident that the true mean difference in leadership scores between masters and bachelors degree prepared nurses IN THE POPULATION is within zero point four points higher in masters nurses to three point two points higher in masters nurses. And we can make this conclusion because the ninety five percent confidence interval indicates the range of scores in which, if we were to repeatedly sample 200 nurses from that same population over and over again, we would expect the mean difference to come up within the range from the lower to the upper confidence interval ninety five percent of the time.

---
class: center, middle, hide-count

# Up next

???

Time to have a go at constructing some confidence intervals in the next exercise.
