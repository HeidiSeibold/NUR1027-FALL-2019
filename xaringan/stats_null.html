<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>stats_null.utf8.md</title>
    <meta charset="utf-8" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
     <head>
        <!-- Place your kit's code here -->
        <script src="https://kit.fontawesome.com/db7db5fd59.js"></script>
      </head>
    <link rel="stylesheet" href="fonts.css" type="text/css" />
    <link rel="stylesheet" href="animate.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">




---
class: left, top, hide-count



```r
set.seed(272)
masters &lt;- data.frame(leadership = rgbeta(n=100, mean=8, var=5^2, min = 3, max = 15),
                      degree = "Masters")
non_masters &lt;- data.frame(leadership = rgbeta(n=100, mean=6.5, var=5^2, min = 3, max = 15),
                          degree = "Bachelors")
data &lt;- rbind(masters, non_masters)

data %&gt;%
  group_by(degree) %&gt;% 
  summarize(average_leadership = mean(leadership))
```

```
## # A tibble: 2 x 2
##   degree    average_leadership
##   &lt;fct&gt;                  &lt;dbl&gt;
## 1 Masters                 8.58
## 2 Bachelors               6.75
```

```r
data %&gt;% 
  specify(leadership ~ degree) %&gt;% 
  calculate("diff in means", order = c("Masters", "Bachelors"))
```

```
## # A tibble: 1 x 1
##    stat
##   &lt;dbl&gt;
## 1  1.82
```

### Difference in means between the two groups in this sample was 1.3


???

In this video, we're going to build a null distribution so you can get your head around what a p-value is and how we can use that information to inform our decision as to whether we should accept or reject a null hypothesis. First, let's get our sample from the population. We have here the leadership capability scores from a sample of two hundred nurses. The leadership capability scores range from 0 to 15, with higher scores meaning greater leadership capability. In our sample, one hundred of the nurses have a masters degree and the other hundred have a bachelors degree. In the sample, the mean leadership capability score for the nurses with a masters degree was eight point six and for the nurses with a bachelors degree it was six point eight. Something to take note of here is that the difference in means between the two groups in our sample was about one point eight points.

---
class: left, top, hide-count


## Understanding the null distribution

Generating a distribution of the difference in means from the null population gives information about whether the observed data are inconsistent with the null hypothesis

???

Now that we have our sample from the population, we can use simulations to build a distribution of differences in means assuming the null hypothesis that there is no difference in leadership scores between the two groups is true. This is called a null distribution. The null distribution we are building consists of randomly shuffled differences in 200 leadership scores, so that the samples don't have any dependency between leadership scores and whether or not nurses have a masters degree. Let's step through how a null distribution is produced to make it easier to understand.

---
class: left, top, hide-count




```r
data %&gt;% 
* specify(leadership ~ degree) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 1, type = "permute") %&gt;%
    calculate(stat = "diff in means", 
              order = c("Masters", "Bachelors"))
```

![](stats_null_files/figure-html/unnamed-chunk-4-1.png)&lt;!-- --&gt;


???

First, we take the data from our sample and specify that we are interested in the relationship between leadership and whether or not nurses have a masters degree. We then state our null hypothesis that there is no difference in leadership scores between groups - in other words they are independent. Then, we generate 1 random shuffle of the data and calculate the difference in mean leadership scores between the masters and bachelors degree groups. We can then plot the results. In the plot the x - or horizontal - axis is the difference in mean leadership score between groups. We can see the result from our sample of 200 nurses on the right hand side - meaning that the mean leadership score was higher in the nurses who had masters degrees in this sample. In this first random shuffle we produce on our way to producing a null distribution, just like in our sample, the mean leadership score was higher in the Masters group. Let's do another random shuffle. 

---
class: left, top, hide-count

## Shuffle 2



```r
data %&gt;% 
  specify(leadership ~ degree) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 1000, type = "permute") %&gt;%
    calculate(stat = "diff in means", order = c("Masters", "Bachelors"))%&gt;%
  ggplot2::ggplot(aes(stat)) + geom_dotplot(binwidth = 0.06,colour="white", fill = "blue", alpha=0.3, method = "histodot" ) +
    scale_y_continuous( limits = c(0,0.8))+
    scale_x_continuous(limits = c(-3,3), breaks = c(seq(-3, 3, by = 1)))+
  theme_minimal()+
  labs(x = "Difference in mean leadership score between groups", y = NULL)+
  geom_point(aes(x=1.82, y=0), colour="red", size=0.5, alpha=0.3)+
  geom_vline(xintercept = 0, size = 1, color = "black")+
  annotate("text", x = -1.8, y = 0.78,
  label = "Leadership scores higher in Bachelors group") +
  annotate("text", x = 1.8, y = 0.78,
  label = "Leadership scores higher in Masters group")
```

![](stats_null_files/figure-html/unnamed-chunk-5-1.png)&lt;!-- --&gt;
???

This time, the Masters degree nurses had a mean leadership score lower than the bachelors group. To build up the null distribution, we simply take lots and lots of random shuffles. Let's do one thousand of them and take a look at the null distribution. 

---
class: left, top, hide-count

### Null distribution

```r
null_distn &lt;- data %&gt;% 
  specify(leadership ~ degree) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 1000, type = "permute") %&gt;%
  calculate(stat = "diff in means", order = c("Masters", "Bachelors"))

visualize(null_distn) +
  shade_p_value(obs_stat = d_hat, direction = NULL)
```

![](stats_null_files/figure-html/unnamed-chunk-6-1.png)&lt;!-- --&gt;

???

What we see when we have completely built the null distribution is that the mean differences in leadership scores were between negative two and positive two, although the majority of differences are between negative one and positive one. In other words, if we assume the null hypothesis is true, and remember, our null hypothesis is that there is no difference in leadership score between groups, it would be totally expected that if we drew lots more samples of 200 nurses from the population the average difference in leadership score between groups that we would observe each time would fall between one point higher or one point lower in the masters group most of the time. The solid red line in the plot is the mean difference in leadership score between groups that we ACTUALLY observed in our sample. The Masters nurses scored their leadership capabilities one point eight points higher on average than nurses with baachelors degrees. So what we can tell already, is that the observed mean difference in leadership capability in our sample does seem a bit extreme compared to this collection of differences from the null distribution. In the next video, I'll move on to demonstrating how a p-value is calculated using this null distribution.

---
class: left, top, hide-count


```r
d_hat &lt;- data %&gt;% 
  specify(leadership ~ degree) %&gt;%
  calculate(stat = "diff in means", order = c("Masters", "Bachelors")) 


null_distn %&gt;%
  ggplot2::ggplot(aes(stat)) + geom_dotplot(binwidth=0.055, method='histodot', colour = "white", fill = "blue", alpha=0.3) +
    scale_y_continuous(NULL, breaks = NULL)+
  theme_minimal()+
  labs(x = "Difference in mean leadership score between groups", y = NULL)+
       annotate("rect", xmin = 1.8, xmax = Inf, ymin = 0, ymax = Inf,
        alpha = .2, fill = "red") +
   annotate("rect", xmin = -1.8, xmax = -Inf, ymin = 0, ymax = Inf,
        alpha = .2, fill = "red") +
  geom_vline(xintercept = 1.82, size = 2, color = "red")
```

![](stats_null_files/figure-html/unnamed-chunk-7-1.png)&lt;!-- --&gt;

```r
null_distn %&gt;%
  visualize(method = "simulation") +
    shade_p_value(d_hat, direction = "both")
```

![](stats_null_files/figure-html/unnamed-chunk-7-2.png)&lt;!-- --&gt;

```r
null_distn %&gt;% 
  get_p_value(obs_stat = d_hat, direction = "two_sided")
```

```
## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1   0.012
```

```r
data %&gt;%
  t_test(leadership ~ degree, alternative="two.sided", order = c("Masters", "Bachelors"), direction = "two.sided")
```

```
## # A tibble: 1 x 6
##   statistic  t_df p_value alternative lower_ci upper_ci
##       &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;    &lt;dbl&gt;
## 1      2.53  198.  0.0121 two.sided      0.404     3.24
```

```r
lowerCI &lt;- d_hat-1.96*sd(null_distn$stat)
upperCI &lt;- d_hat+1.96*sd(null_distn$stat)
#or
ci &lt;- null_distn %&gt;%
  get_confidence_interval(type = "se", point_estimate = d_hat)

null_distn %&gt;%
  visualize(method = "simulation") +
  shade_confidence_interval(c(ci$lower,ci$upper) )
```

![](stats_null_files/figure-html/unnamed-chunk-7-3.png)&lt;!-- --&gt;
???

What we can do now, is go ahead and calculate the p-value. The p-value is the probability that we would observe a result either as or more extreme than we got from our sample, assuming the null hypothsis was true. So in our sample the difference in mean leadership scores between groups was one point eight points. All we have to do to get the p-value is work out how many times out of the 1000 random shuffles that made up the null distribution was the difference in means more extreme than one point eight. As it turns out, in only 12 out of the 1000 random shuffles that made up the null distribution did the difference in means turn out to be more extreme than the one point eight we observed in our sample. This equates to a p-value of point zero one two or about a 1% probability of observing such an extreme event assuming the null hypothesis was true. One final note is that because we didn't specify a direction for our alternative hypothesis, we just simply stated that the difference in means between nurses with and without a masters degree would not be zero, the p-value takes into consideration values that were more extreme than what we observed from both sides of the curve - so both positive one point eight and negative one point eight points. 

---
class: center, middle, hide-count

### The "goal" is to disprove the null hypothesis. 

???

But what can we conclude from this p-value. Remember back to earlier in this video when we established that the GOAL of hypothesis testing for statistical inference was to disprove the null hypothesis. We have established some pretty compelling evidence against the null hypothesis. That there was only about a one percent probability of observing a result as or more extreme than the one point eight difference in mean score between groups in our sample strongly suggests that the null hypothesis is not true. In statistical terms, we would say that based on these results, we should therefore reject the null hypothesis that there was no difference in leadership scores between groups. I'm sure you would have all seen or heard p-values lower than the traditional benchmark of point zero five as being statistically significant. 

---

class: center, middle, hide-count

# Up next

???

Ok, we've covered a LOT in this video but, as I'm sure you've heard, p-values are a bit notorious for being misinterpreted. So I hope this video has helped you to understand exactly what a p-value is testing. In the next section I've set up an exercise for you to practice setting null and alternative hypotheses and building a null distribution to test the null hypothesis.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
