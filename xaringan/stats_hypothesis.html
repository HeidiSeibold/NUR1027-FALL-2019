<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>stats_hypothesis.utf8.md</title>
    <meta charset="utf-8" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
     <head>
        <!-- Place your kit's code here -->
        <script src="https://kit.fontawesome.com/db7db5fd59.js"></script>
      </head>
    <link rel="stylesheet" href="fonts.css" type="text/css" />
    <link rel="stylesheet" href="animate.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">




class: left, middle, hide-count

### Statistical inference is the process of making claims about a population based on information from a sample. 

???

As we have learnt, statistical inference is the process of making claims about a population based on information from a sample. We've already learnt about one way to do inference. We used the standard error to construct confidence intervals for a sample mean in the last exercise. Now we're going to extend this way of thinking to the common situation in quantitative research, where we are interested in making comparisons between groups.
 
---

class: left, top, hide-count
## Statistical Inference

- A **statistical inference** helps to make decisions using data.


- An *inference* in general is an uncertain conclusion.

???

Before we dive into this, I want to highlight some further important principles of statistical inference. The purpose of statistical inference is to help us make decisions using data. However, we shouldn't forget that inference is an uncertain conclusion and our interpretations of the results from statistical analyses always need to take that uncertainty into account. But let's dive in now to hypothesis testing. The most common statistical approach to making comparisons between groups of participants in quantitative research is within a framework known as frequentist statistics that relies on hypothesis testing.

---
class: left, top, hide-count

## The hypotheses

Two claims:

1. There is no difference in leadership capability of nurses who have and have not completed a masters degree.  This is the **null hypothesis**, written `\(H_0\)`. The difference in leadership scores is **zero**.
$$ H_0: mean(masters)-mean(non-masters)=0 $$

--

2. There is a difference in leadership capability of nurses who have and have not completed a masters degree. This is the **alternative hypothesis**. The difference in mean scores between groups is **not zero**
$$ H_1: mean(masters)-mean(non-masters)â‰ 0$$
--


???

Consider this hypothetical situation. Say we are interested in determining if nurses who have completed a masters degree have greater leadership capabilities than nurses who do not have a masters. To put this into a framework that fits with statistical inference, the first step is to assume that there is no difference in leadership capabilities between the two populations, nurses with and without masters degrees. In statistical terms, this is the null hypothesis. Our statement that there IS a difference in leadership capability between nurses who have completed a masters degree is formally termed the alternative hypothesis. The second step in statistical inference after setting the null and alternative hypotheses, is to use data from a sample drawn from those populations to argue AGAINST the null hypothesis, which is that there is no true difference between the two groups of nurses. 

---
class: center, middle, hide-count

### The "goal" is to disprove the null hypothesis. 

???

In simpler terms, the goal is to DISPROVE the null hypothsis so that you can claim the alternative hypothesis is true. So how are we going to do that. Let's go through the steps now.


---
class: left, top, hide-count



```r
set.seed(272)
(masters &lt;- data.frame(leadership = rgbeta(n=100, mean=8, var=5^2, min = 3, max = 15),
                      degree = "Masters"))
```

```
##     leadership  degree
## 1    14.980677 Masters
## 2    12.966212 Masters
## 3     3.000461 Masters
## 4    14.994906 Masters
## 5     8.057211 Masters
## 6     5.637299 Masters
## 7     7.384774 Masters
## 8    14.087625 Masters
## 9    14.998793 Masters
## 10   14.925928 Masters
## 11    7.777908 Masters
## 12    3.000034 Masters
## 13    4.514135 Masters
## 14   14.948776 Masters
## 15    3.124302 Masters
## 16   14.983945 Masters
## 17   14.999902 Masters
## 18    9.976511 Masters
## 19   12.709966 Masters
## 20    3.000468 Masters
## 21    7.158958 Masters
## 22   12.372685 Masters
## 23    3.016101 Masters
## 24    3.626464 Masters
## 25    6.738234 Masters
## 26    3.000164 Masters
## 27   10.495700 Masters
## 28    3.003386 Masters
## 29   11.966062 Masters
## 30    3.000031 Masters
## 31    4.206154 Masters
## 32    3.046791 Masters
## 33   14.987106 Masters
## 34    4.759220 Masters
## 35   14.291070 Masters
## 36   11.969472 Masters
## 37    9.469593 Masters
## 38   14.999997 Masters
## 39    3.000000 Masters
## 40    3.060699 Masters
## 41   14.674546 Masters
## 42    3.002690 Masters
## 43    9.663803 Masters
## 44    3.000023 Masters
## 45    5.169532 Masters
## 46    3.000000 Masters
## 47    6.754127 Masters
## 48    3.000000 Masters
## 49    4.008469 Masters
## 50   13.713208 Masters
## 51   14.757614 Masters
## 52    3.018586 Masters
## 53   14.996217 Masters
## 54   15.000000 Masters
## 55    3.000001 Masters
## 56    9.209263 Masters
## 57   12.336424 Masters
## 58    9.570860 Masters
## 59   11.641366 Masters
## 60    4.593963 Masters
## 61    3.308568 Masters
## 62    3.808311 Masters
## 63   14.255848 Masters
## 64   14.418277 Masters
## 65    3.149266 Masters
## 66    3.312241 Masters
## 67    3.164921 Masters
## 68    5.612953 Masters
## 69   12.792360 Masters
## 70    4.559413 Masters
## 71    3.496918 Masters
## 72    3.032482 Masters
## 73   14.520898 Masters
## 74    3.310784 Masters
## 75   14.939837 Masters
## 76   13.562758 Masters
## 77   14.517015 Masters
## 78    3.000000 Masters
## 79    3.000085 Masters
## 80   14.999930 Masters
## 81   14.497622 Masters
## 82    3.037390 Masters
## 83    3.032437 Masters
## 84    6.555710 Masters
## 85   14.928160 Masters
## 86   14.987749 Masters
## 87    8.749113 Masters
## 88   12.393505 Masters
## 89    3.743524 Masters
## 90   11.377919 Masters
## 91   12.420987 Masters
## 92   13.644590 Masters
## 93   12.546144 Masters
## 94   14.481577 Masters
## 95    3.000052 Masters
## 96   14.851725 Masters
## 97    3.000309 Masters
## 98    3.063474 Masters
## 99    3.435775 Masters
## 100  14.907065 Masters
```

```r
mean(masters$leadership)
```

```
## [1] 8.577661
```

```r
(non_masters &lt;- data.frame(leadership = rgbeta(n=100, mean=6.5, var=5^2, min = 3, max = 15),
                          degree = "Bachelors"))
```

```
##     leadership    degree
## 1     3.000000 Bachelors
## 2     3.000250 Bachelors
## 3     3.002140 Bachelors
## 4     3.000028 Bachelors
## 5     3.005512 Bachelors
## 6     3.000000 Bachelors
## 7     3.000000 Bachelors
## 8    10.290527 Bachelors
## 9    14.908218 Bachelors
## 10   14.062256 Bachelors
## 11    4.096467 Bachelors
## 12    3.000399 Bachelors
## 13    3.276330 Bachelors
## 14   14.349768 Bachelors
## 15    3.677491 Bachelors
## 16    3.000001 Bachelors
## 17    3.000000 Bachelors
## 18    3.000000 Bachelors
## 19    7.046583 Bachelors
## 20   12.587959 Bachelors
## 21    3.188462 Bachelors
## 22    3.000000 Bachelors
## 23    3.000000 Bachelors
## 24    3.000000 Bachelors
## 25    3.000000 Bachelors
## 26    3.000000 Bachelors
## 27    3.000000 Bachelors
## 28    3.000111 Bachelors
## 29    3.018967 Bachelors
## 30   14.996756 Bachelors
## 31   14.959636 Bachelors
## 32   14.999989 Bachelors
## 33    4.828601 Bachelors
## 34    3.180997 Bachelors
## 35   15.000000 Bachelors
## 36   14.999965 Bachelors
## 37    3.099263 Bachelors
## 38    3.000000 Bachelors
## 39    3.000000 Bachelors
## 40    3.000001 Bachelors
## 41   14.989403 Bachelors
## 42    3.000000 Bachelors
## 43    9.358087 Bachelors
## 44    3.660556 Bachelors
## 45   14.922546 Bachelors
## 46    3.006152 Bachelors
## 47    3.000000 Bachelors
## 48    3.009002 Bachelors
## 49    3.000002 Bachelors
## 50    9.460008 Bachelors
## 51   14.997479 Bachelors
## 52    3.000000 Bachelors
## 53    3.000001 Bachelors
## 54    3.000039 Bachelors
## 55   14.985200 Bachelors
## 56    3.194247 Bachelors
## 57   15.000000 Bachelors
## 58   14.999656 Bachelors
## 59   13.471708 Bachelors
## 60    3.000060 Bachelors
## 61    3.000000 Bachelors
## 62    3.000001 Bachelors
## 63    3.000000 Bachelors
## 64   15.000000 Bachelors
## 65    3.001880 Bachelors
## 66   15.000000 Bachelors
## 67   14.400976 Bachelors
## 68   14.999930 Bachelors
## 69    3.000000 Bachelors
## 70   14.983940 Bachelors
## 71    8.950970 Bachelors
## 72    5.026099 Bachelors
## 73    3.087565 Bachelors
## 74    3.000000 Bachelors
## 75    3.915439 Bachelors
## 76    3.000980 Bachelors
## 77    3.000144 Bachelors
## 78   13.874223 Bachelors
## 79    3.000001 Bachelors
## 80    3.000000 Bachelors
## 81    3.000000 Bachelors
## 82    7.596263 Bachelors
## 83    3.116309 Bachelors
## 84    3.000000 Bachelors
## 85   14.512371 Bachelors
## 86    3.000000 Bachelors
## 87   14.999997 Bachelors
## 88    3.012590 Bachelors
## 89   14.999979 Bachelors
## 90    9.428866 Bachelors
## 91    3.000006 Bachelors
## 92    3.000003 Bachelors
## 93   14.078901 Bachelors
## 94    3.128868 Bachelors
## 95   14.963209 Bachelors
## 96    3.000005 Bachelors
## 97    3.000015 Bachelors
## 98    3.000000 Bachelors
## 99   13.719620 Bachelors
## 100   3.000000 Bachelors
```

```r
data &lt;- rbind(masters, non_masters)

data %&gt;% 
  specify(leadership ~ degree) %&gt;% 
  calculate("diff in means", order = c("Masters", "Bachelors"))
```

```
## # A tibble: 1 x 1
##    stat
##   &lt;dbl&gt;
## 1  1.82
```

### Difference in means between the two groups in this sample was 1.3


???

First, let's create a dataset of leadership capability scores from a sample of two hundred nurses. One hundred of the nurses have a masters degree and the other hundred have a bachelors degree. In just this sample we can calculatate that the mean leadership capability score for the nurses with a masters degree was 4.8 and for the nurses with a bachelors degree it was 3.5. Don't concern yourself with the code, all you have to note here is that the difference in means between the two groups in this sample was 1.3.

---
class: left, top, hide-count


## Understanding the null distribution

Generating a distribution of the difference in means from the null population gives information about whether the observed data are inconsistent with the null hypothesis

???

We can use random sampling to build a distribution of differences in means assuming the null hypothesis that there is no difference in leadership scores between groups is true. The null distribution consists of randomly shuffled differences in leadership scores, so that the samples don't have any dependency between leadership scores and whether or not nurses have a masters degree. Let's step through how a null distribution is produced to make it easier to understand.

---
class: left, top, hide-count

## Shuffle 1

```r
d_hat &lt;- data %&gt;% 
  specify(leadership ~ degree) %&gt;% 
  calculate("diff in means", order = c("Masters", "Bachelors"))
```



```r
set.seed(272)
data %&gt;% 
  specify(leadership ~ degree) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 1000, type = "bootstrap") %&gt;% 
  calculate(stat = "diff in means", order = c("Masters", "Bachelors")) %&gt;%
  get_confidence_interval(type = "se", point_estimate = d_hat)
```

```
## Warning: You have given `type = "bootstrap"`, but `type` is expected to be
## `"permute"`. This workflow is untested and the results may not mean what
## you think they mean.
```

```
## # A tibble: 1 x 2
##   lower upper
##   &lt;dbl&gt; &lt;dbl&gt;
## 1 0.417  3.23
```

```r
set.seed(272)
data %&gt;% 
  specify(leadership ~ degree) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 1000, type = "permute") %&gt;% 
  calculate(stat = "diff in means", order = c("Masters", "Bachelors")) %&gt;%
  get_p_value(obs_stat = d_hat, direction = "right")
```

```
## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1   0.011
```

```r
set.seed(272)
data %&gt;% 
t_test(leadership ~ degree, order = c("Masters", "Bachelors"), alternative = "two.sided")
```

```
## # A tibble: 1 x 6
##   statistic  t_df p_value alternative lower_ci upper_ci
##       &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;    &lt;dbl&gt;
## 1      2.53  198.  0.0121 two.sided      0.404     3.24
```


???

First, we take the data from our sample and specify that we are interested in the relationship between leadership and whether or not nurses have a masters degree. We then state our null hypothesis that there is no difference in leadership scores between groups - in other words they are independent. Then we generate 1 random shuffle of the data that we have and take a look at the results. In this first shuffle, unlike in our sample, the mean leadership score was lower in the Masters group. Let's do another random shuffle. 

---
class: left, top, hide-count

## Shuffle 2



```r
data %&gt;% 
  specify(leadership ~ degree) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 1, type = "permute") %&gt;% 
  group_by(degree) %&gt;% 
  summarize(average_leadership = mean(leadership))
```

```
## # A tibble: 2 x 2
##   degree    average_leadership
##   &lt;fct&gt;                  &lt;dbl&gt;
## 1 Masters                 7.51
## 2 Bachelors               7.82
```
???

This time, the Masters degree nurses had a mean leadership score higher than the bachelors group. To build up the null distribution, we simply take lots and lots of random shuffles. Now, let's do one thousand shuffles. 

---
class: left, top, hide-count

### Null distribution

```r
null_distn &lt;- data %&gt;% 
  specify(leadership ~ degree) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 1000, type = "permute") %&gt;%
  calculate(stat = "diff in means", order = c("Masters", "Bachelors"))
visualize(null_distn) +
  shade_p_value(obs_stat = d_hat, direction = NULL)
```

![](stats_hypothesis_files/figure-html/unnamed-chunk-6-1.png)&lt;!-- --&gt;

???

What we see when we have completely built the null distribution is that the mean differences in leadership scores were between negative two and positive two, although the majority of differences are between negative one and positive one. In other words, if we assume the null hypothesis is true and the null hypothesis is that there is no difference in leadership score between groups, it would be totally expected that if we drew lots more samples of 200 nurses from the population the average difference in leadership score between groups that we would observe each time would fall between one point higher or one point lower in the masters group most of the time. The solid red line in the plot is the mean difference in leadership score between groups that we ACTUALLY observed in our sample. The Masters nurses scored their leadership capabilities one point eight points higher on average than nurses with baachelors degrees. So what we can tell already without yet calculating any p-values or anything, is that the observed mean difference in leadership capability in our sample does seem a bit extreme compared to this collection of differences from the null distribution. 

---
class: left, top, hide-count


```r
d_hat &lt;- data %&gt;% 
  specify(leadership ~ degree) %&gt;%
  calculate(stat = "diff in means", order = c("Masters", "Bachelors")) 


set.seed(272)
data %&gt;% 
  specify(leadership ~ degree) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 1000, type = "permute") %&gt;% 
  calculate(stat = "diff in means", order = c("Masters", "Bachelors")) %&gt;%
  visualize(method = "simulation")+
    shade_p_value(d_hat, direction = "both")
```

![](stats_hypothesis_files/figure-html/unnamed-chunk-7-1.png)&lt;!-- --&gt;

```r
null_distn %&gt;% 
  get_p_value(obs_stat = d_hat, direction = "two_sided")
```

```
## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1   0.022
```
???

What we can do now, is go ahead and calculate the p-value. The p-value is the probability that we would observe a result as or more extreme than we did in our sample, assuming the null hypothsis was true. So in our sample the difference in mean leadership scores between groups was one point eight points. All we have to do to get the p-value is work out how many times out of the 1000 random shuffles that made up the null distribution was the difference in means more extreme than one point eight. The p-value was point zero two two. Or in other words, only 22 out of the 1000 random shuffles that made up the null distribution did the difference in means turn out to be more extreme than the one point eight we observed in our sample. One final note is that because we didn't specify a direction for our alternative hypothesis, we just simply stated that the difference in means between nurses with and without a masters degree would not be zero, the p-value takes into consideration values that were more extreme than what we observed from both sides of the curve - so both positive one point eight and negative one point eight points. 

---

class: center, middle, hide-count

# Up next

???

We've covered a lot in this video but I hope it's helped you understand what exactly a p-value is testing. p-values are a bit notorious for being misinterpreted. In the next section I've set up an exercise for you to practice setting null and alternative hypotheses and building a null distribution.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create();
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
